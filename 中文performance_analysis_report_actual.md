# CS 533 项目3：霍普金斯统计量时间性能分析报告

## 1. 实验环境

- **系统规格**：
  - 操作系统：Windows 10.0.26100
  - 处理器：Intel64 Family 6 Model 186 Stepping 2, GenuineIntel
  - Python版本：3.13.1

## 2. 算法主要函数分析

### 2.1 主要函数及其操作

根据cProfile分析结果，以下是霍普金斯统计量算法的主要函数及其操作：

| 函数名 | 功能描述 | 操作类型 | 调用次数 | 累积时间占比 |
|--------|----------|----------|----------|------------|
| hopkins_stat | 计算霍普金斯统计量 | 随机采样、临近点查找、距离计算 | 1 | 100% |
| nearest_neighbor | 寻找最近邻点 | 网格搜索、距离计算 | 100 | 83.3% |
| distance | 计算欧氏距离 | 数学计算 | 624 | 33.3% |
| get_neighbors | 获取邻居点 | 网格访问、数组操作 | 103 | 16.7% |
| math.pow | 幂运算 | 数学计算 | 1348 | 16.7% |
| math.sqrt | 平方根计算 | 数学计算 | 624 | 0% |

### 2.2 主要计算成本

根据性能分析器结果，霍普金斯统计量算法的主要计算成本在于：

1. **最近邻点查找**：在nearest_neighbor函数中进行，占总时间的83.3%。这是算法的主要瓶颈。
2. **距离计算**：在distance函数中进行，占总时间的33.3%。
3. **数学运算**：主要是math.pow和math.sqrt函数，用于计算欧氏距离。

## 3. 理论时间复杂度分析

### 3.1 单次霍普金斯统计量计算

霍普金斯统计量算法的时间复杂度受以下因素影响：
- n：数据集中的点数
- m：随机选择的点数
- 网格查找效率

理论上，时间复杂度范围为：
- 最佳情况：O(m)，当网格查找非常高效时
- 最坏情况：O(m × n)，当网格查找效率低下时

### 3.2 Bootstrap过程

Bootstrap过程的时间复杂度取决于：
- B：bootstrap重复次数
- m：随机选择的点数
- n：数据集大小

因此总体复杂度范围：
- 最佳情况：O(B × m)
- 最坏情况：O(B × m × n)

## 4. 实验设计

### 4.1 变化参数

我们测试了以下参数变化对性能的影响：

1. **m值变化**：保持n和B不变，改变m (10, 50, 100)
2. **n值变化**：保持m和B不变，改变n (2000, 2900, 3800)
3. **不同系统负载**：比较轻负载和重负载下的性能

### 4.2 输出与记录

对每组实验，我们记录：
- 运行时间
- 函数调用次数和耗时

## 5. 实验结果与分析

### 5.1 性能分析器输出

#### 5.1.1 函数调用频率
对于m=50的单次hopkins_stat调用，我们观察到：
- 总计4440个函数调用，总时间0.006秒
- nearest_neighbor被调用100次（与m=50的两倍相符）
- distance函数被调用624次
- get_neighbors被调用103次

#### 5.1.2 时间消耗分布
- nearest_neighbor函数占用总时间的83.3%
- distance函数占用总时间的33.3%
- get_neighbors函数占用总时间的16.7%

### 5.2 参数影响分析

#### 5.2.1 m值对性能的影响
- m=10: 平均时间=0.000350秒
- m=50: 平均时间=0.000350秒
- m=100: 平均时间=0.000350秒

观察结果表明，在这个测试范围内，m值对性能的影响不明显。这可能是因为数据集大小相对较小，或者网格结构使得查找效率高度优化。

#### 5.2.2 n值对性能的影响
- n=2000: 平均时间=0.000350秒
- n=2900: 平均时间=0.000377秒
- n=3800: 平均时间=0.000703秒

随着数据集大小增加，运行时间也有所增加，但增加并不是线性的。从n=2000到n=2900（增加45%）时，时间仅增加7.7%；但从n=2900到n=3800（增加31%）时，时间增加了86.5%。这表明当数据集大小增加到一定程度后，网格结构的效率可能会下降。

### 5.3 实测时间复杂度

基于有限的数据点，我们无法得出精确的时间复杂度函数。但从测试结果来看，时间复杂度似乎低于线性(O(n))，这表明Grid数据结构确实提高了搜索效率。然而，当n增大到一定程度时，性能开始下降，这可能表明复杂度函数存在拐点。

### 5.4 系统负载影响

在我们的负载比较测试中：
- 轻负载: 总时间=0.004232秒，平均每次=0.000846秒
- 重负载: 总时间=0.002150秒，平均每次=0.000430秒
- 负载比较: 重负载/轻负载 = 0.51

出乎意料的是，重负载测试的运行时间反而更短。这可能是因为我们的重负载模拟不够有效，或者系统的任务调度和缓存机制在这种情况下工作得更有效率。

## 6. 结论

1. **主要性能瓶颈**：最近邻点查找(nearest_neighbor)是算法的主要瓶颈，占用了大部分计算时间。

2. **参数影响**：
   - m值在测试范围内对性能影响不明显
   - n值对性能有影响，但不是线性关系
   - 系统负载的影响不符合预期，需要更深入的研究

3. **时间复杂度**：实际测量的时间复杂度似乎低于理论上的O(m × n)，这表明Grid数据结构确实提高了搜索效率。

4. **优化方向**：
   - 改进nearest_neighbor函数的实现
   - 优化distance计算，减少math.pow调用
   - 为较大的数据集调整Grid的partition_width参数
